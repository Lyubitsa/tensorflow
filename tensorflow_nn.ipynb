{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d570322a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0411c54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#physical_devices = tf.config.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "987f44c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1291e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9477baa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b0214ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 28*28).astype(\"float32\") / 255.0\n",
    "x_test = x_test.reshape(-1, 28*28).astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb7fdd1",
   "metadata": {},
   "source": [
    "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "This line specifies the loss function to be used during training. In this case, it's using Sparse Categorical Crossentropy. This loss function is commonly used for classification problems where the labels are integers (sparse), and the model outputs logits (the raw, unnormalized predictions). The parameter from_logits=True indicates that the model's output doesn't need to be normalized to probabilities before calculating the loss; the normalization will be handled internally.\n",
    "\n",
    "optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    " This line specifies the optimizer to be used during training. Here, it's using the Adam optimizer with a learning rate of 0.001. Adam is a popular optimizer for training deep neural networks. It adapts the learning rate for each parameter during training based on the moving averages of the gradients.\n",
    "\n",
    "metrics=[\"accuracy\"],\n",
    " This line specifies the metrics that will be used to evaluate the model during training and testing. In this case, it's using accuracy, which is a common metric for classification problems. Accuracy measures the proportion of correctly classified examples out of the total number of examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cd73c315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5775 - accuracy: 0.8247\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2923 - accuracy: 0.9139\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2234 - accuracy: 0.9340\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1768 - accuracy: 0.9467\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1431 - accuracy: 0.9569\n",
      "313/313 [==============================] - 0s 615us/step - loss: 17.9645 - accuracy: 0.9380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[17.964534759521484, 0.9380000233650208]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sequantial API (one input, one output)\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(28*28)),#debugging\n",
    "        layers.Dense(512, activation = 'relu'),\n",
    "        layers.Dense(256, activation = 'relu'),\n",
    "        layers.Dense(10),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#print(model.summary()) # debugging\n",
    "#import sys\n",
    "#sys.exit()\n",
    "\n",
    "model.compile(\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.fit(x_train,y_train, batch_size=32, epochs=5,verbose=1)\n",
    "model.evaluate(x_test,y_test, batch_size=32,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "af3a5dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_28 (InputLayer)       [(None, 784)]             0         \n",
      "                                                                 \n",
      " first_layer (Dense)         (None, 512)               401920    \n",
      "                                                                 \n",
      " second_layer (Dense)        (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 535,818\n",
      "Trainable params: 535,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Number of weights after calling the model: 6\n",
      "Number of weights after calling the model: 6\n",
      "Epoch 1/4\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.6309 - accuracy: 0.8074\n",
      "Epoch 2/4\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2921 - accuracy: 0.9144\n",
      "Epoch 3/4\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2159 - accuracy: 0.9360\n",
      "Epoch 4/4\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1662 - accuracy: 0.9498\n",
      "313/313 [==============================] - 0s 648us/step - loss: 26.0927 - accuracy: 0.9489\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[26.092687606811523, 0.9488999843597412]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Functional API (more flexible then sequantial api)\n",
    "inputs = keras.Input(shape=(28*28))\n",
    "x = layers.Dense(512, activation = 'relu', name='first_layer')(inputs)\n",
    "x = layers.Dense(256, activation = 'relu', name='second_layer')(x)\n",
    "outputs = layers.Dense(10, activation = 'softmax')(x)\n",
    "model =keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    #optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "    #optimizer=tf.keras.optimizers.legacy.Nadam(learning_rate=0.001),\n",
    "    optimizer=tf.keras.optimizers.legacy.RMSprop(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    " # accuracy increasing with  training the model longer, but not too much\n",
    "model.fit(x_train,y_train, batch_size=32, epochs=4,verbose=1)\n",
    "model.evaluate(x_test,y_test, batch_size=32,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d3c4cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d4dea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fd456d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc27890",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
